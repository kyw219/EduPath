import openai
import pymysql
import json
import uuid
from dotenv import load_dotenv
import os
from typing import List, Dict

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv('../.env')

# é…ç½®
client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

def get_db_connection():
    return pymysql.connect(
        host=os.getenv('TIDB_HOST'),
        port=int(os.getenv('TIDB_PORT', 4000)),
        user=os.getenv('TIDB_USER'),
        password=os.getenv('TIDB_PASSWORD'),
        database=os.getenv('TIDB_DATABASE'),
        charset='utf8mb4',
        ssl={'check_hostname': False, 'verify_mode': 0}
    )

def analyze_chat(chat_history: List[Dict]) -> Dict:
    """
    åˆ†æèŠå¤©è®°å½•ï¼Œæå–ç”¨æˆ·ä¿¡æ¯å¹¶è¿”å›analysis_id
    å¯¹åº”å‰ç«¯: analyzeChat(chatHistory)
    """
    print("ğŸ”„ åˆ†æèŠå¤©è®°å½•...")
    
    # ç”Ÿæˆsession_id
    session_id = str(uuid.uuid4())
    
    # æå–ç”¨æˆ·ä¿¡æ¯
    user_messages = [msg['content'] for msg in chat_history if msg['role'] == 'user']
    user_profile = ' '.join(user_messages)
    
    print("ğŸ”„ å‘é‡åŒ–ç”¨æˆ·æ¡£æ¡ˆ...")
    # å‘é‡åŒ–ç”¨æˆ·æ¡£æ¡ˆ
    response = client.embeddings.create(
        input=user_profile,
        model="text-embedding-ada-002"
    )
    profile_vector = response.data[0].embedding
    
    # å­˜å‚¨åˆ°æ•°æ®åº“
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            cursor.execute("""
                INSERT INTO user_sessions (
                    session_id, chat_messages, user_profile, 
                    profile_embedding, status
                ) VALUES (%s, %s, %s, %s, %s)
            """, (
                session_id,
                json.dumps(chat_history),
                user_profile,
                str(profile_vector),
                'analyzed'
            ))
        conn.commit()
        print(f"âœ… ç”¨æˆ·ä¼šè¯åˆ›å»ºæˆåŠŸ: {session_id}")
    finally:
        conn.close()
    
    return {
        "analysis_id": session_id,
        "status": "analyzing", 
        "message": "Analyzing 50+ programs based on your profile..."
    }

def get_schools(analysis_id: str) -> Dict:
    """
    åŸºäºanalysis_idè·å–åŒ¹é…çš„å­¦æ ¡
    å¯¹åº”å‰ç«¯: getSchools(analysisId)
    """
    print(f"ğŸ”„ è·å–å­¦æ ¡åŒ¹é…ç»“æœ: {analysis_id}")
    
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            # è·å–ç”¨æˆ·æ¡£æ¡ˆå‘é‡
            cursor.execute("""
                SELECT profile_embedding FROM user_sessions 
                WHERE session_id = %s
            """, (analysis_id,))
            
            result = cursor.fetchone()
            if not result:
                raise Exception("Session not found")
            
            user_vector = result[0]
            
            print("ğŸ”„ æ‰§è¡Œå‘é‡æœç´¢...")
            # æœç´¢target schools (ç›¸ä¼¼åº¦é«˜çš„)
            cursor.execute("""
                SELECT 
                    id, school_name, program_name, country_region,
                    qs_ranking, degree_type, duration, program_details,
                    VEC_COSINE_DISTANCE(embedding, %s) AS similarity
                FROM schools 
                ORDER BY similarity ASC 
                LIMIT 3
            """, (user_vector,))
            
            target_results = cursor.fetchall()
            target_schools = []
            for row in target_results:
                target_schools.append({
                    "school": row[1],
                    "program": row[2],
                    "match_score": int((1 - row[8]) * 100),  # è½¬æ¢ä¸ºåŒ¹é…åˆ†æ•°
                    "deadline": "2025-01-15",  # ç¤ºä¾‹æ•°æ®
                    "requirements": "Basic background sufficient",
                    "tuition": "$43,000",
                    "employment_rate": "92%",
                    "reason": f"Great match for your background in {row[3]}"
                })
            
            # æœç´¢reach schools (ç›¸ä¼¼åº¦ä¸­ç­‰ï¼Œä½†æ’åæ›´é«˜çš„)
            cursor.execute("""
                SELECT 
                    id, school_name, program_name, country_region,
                    qs_ranking, degree_type, duration, program_details,
                    VEC_COSINE_DISTANCE(embedding, %s) AS similarity
                FROM schools 
                WHERE qs_ranking <= 20
                ORDER BY similarity ASC 
                LIMIT 2
            """, (user_vector,))
            
            reach_results = cursor.fetchall()
            reach_schools = []
            for row in reach_results:
                reach_schools.append({
                    "school": row[1],
                    "program": row[2], 
                    "match_score": max(50, int((1 - row[8]) * 100) - 20),  # é™ä½åˆ†æ•°
                    "gaps": ["Advanced Math", "Research Experience"],
                    "suggestions": "Complete prerequisite courses and gain research experience",
                    "deadline": "2025-12-01",
                    "tuition": "$77,000",
                    "requirements": "Strong academic background required",
                    "employment_rate": "98%",
                    "reason": f"Top-tier program at {row[1]}"
                })
            
            # æ›´æ–°æ•°æ®åº“
            schools_data = {
                "target_schools": target_schools,
                "reach_schools": reach_schools
            }
            
            cursor.execute("""
                UPDATE user_sessions 
                SET target_schools = %s, reach_schools = %s
                WHERE session_id = %s
            """, (
                json.dumps(target_schools),
                json.dumps(reach_schools), 
                analysis_id
            ))
            
        conn.commit()
        print(f"âœ… æ‰¾åˆ° {len(target_schools)} ä¸ªç›®æ ‡å­¦æ ¡ï¼Œ{len(reach_schools)} ä¸ªå†²åˆºå­¦æ ¡")
        
    finally:
        conn.close()
    
    return schools_data

def get_timeline(analysis_id: str) -> Dict:
    """
    åŸºäºanalysis_idç”Ÿæˆç”³è¯·æ—¶é—´çº¿
    å¯¹åº”å‰ç«¯: getTimeline(analysisId)
    """
    print(f"ğŸ”„ ç”Ÿæˆç”³è¯·æ—¶é—´çº¿: {analysis_id}")
    
    # ç”Ÿæˆç¤ºä¾‹æ—¶é—´çº¿æ•°æ®
    timeline_data = {
        "timeline": [
            {
                "phase": "Background Building",
                "period": "2025-01 to 2025-03", 
                "color": "#10B981",
                "tasks": [
                    {
                        "task": "Complete Prerequisites",
                        "deadline": "2025-02-15",
                        "status": "pending",
                        "priority": "high",
                        "reason": "Required for target programs",
                        "cost": "$1,200"
                    }
                ]
            },
            {
                "phase": "Application Prep",
                "period": "2025-04 to 2025-08",
                "color": "#3B82F6", 
                "tasks": [
                    {
                        "task": "GRE Preparation & Test",
                        "deadline": "2025-06-15",
                        "status": "upcoming", 
                        "priority": "high",
                        "reason": "Required for most programs",
                        "cost": "$220"
                    }
                ]
            }
        ],
        "key_deadlines": [
            {"date": "2025-01-15", "event": "Target School Applications Due", "type": "application"},
            {"date": "2025-12-01", "event": "Reach School Applications Due", "type": "application"}
        ],
        "total_estimated_cost": "$5,500",
        "total_tasks": 12,
        "completion_rate": 0
    }
    
    # æ›´æ–°æ•°æ®åº“
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            cursor.execute("""
                UPDATE user_sessions 
                SET timeline_data = %s, status = 'completed'
                WHERE session_id = %s
            """, (json.dumps(timeline_data), analysis_id))
        conn.commit()
        print("âœ… æ—¶é—´çº¿ç”Ÿæˆå®Œæˆ")
    finally:
        conn.close()
    
    return timeline_data

# æ¼”ç¤ºå®Œæ•´æµç¨‹
def demo_full_flow():
    print("ğŸš€ æ¼”ç¤ºå®Œæ•´APIæµç¨‹")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿå‰ç«¯èŠå¤©æ•°æ®
    chat_history = [
        {"role": "assistant", "content": "Hi! Tell me about your background..."},
        {"role": "user", "content": "æˆ‘æ˜¯ç»æµå­¦æœ¬ç§‘ç”Ÿï¼ŒGPA 3.6ï¼Œæƒ³è½¬ä¸“ä¸šåˆ°è®¡ç®—æœºç§‘å­¦ã€‚æˆ‘è‡ªå­¦äº†Pythonå’ŒJavaï¼Œåšè¿‡å‡ ä¸ªWebå¼€å‘é¡¹ç›®ï¼Œå¸Œæœ›ç”³è¯·ç¾å›½çš„è®¡ç®—æœºç§‘å­¦ç¡•å£«é¡¹ç›®ã€‚æˆ‘å¯¹äººå·¥æ™ºèƒ½å’Œæ•°æ®ç§‘å­¦ç‰¹åˆ«æ„Ÿå…´è¶£ã€‚"},
        {"role": "assistant", "content": "Got it! Any location/budget preferences?"},
        {"role": "user", "content": "æˆ‘å¸Œæœ›åœ¨ç¾å›½ï¼Œé¢„ç®—åœ¨5ä¸‡ç¾å…ƒä»¥å†…ï¼Œå€¾å‘äºè¥¿æµ·å²¸çš„å­¦æ ¡ã€‚"}
    ]
    
    try:
        # æ­¥éª¤1: åˆ†æèŠå¤©
        print("\nğŸ“ æ­¥éª¤1: åˆ†æèŠå¤©è®°å½•")
        analysis_result = analyze_chat(chat_history)
        analysis_id = analysis_result["analysis_id"]
        print(f"Analysis ID: {analysis_id}")
        
        # æ­¥éª¤2: è·å–å­¦æ ¡åŒ¹é…
        print(f"\nğŸ« æ­¥éª¤2: è·å–å­¦æ ¡åŒ¹é…")
        schools_result = get_schools(analysis_id)
        print(f"ç›®æ ‡å­¦æ ¡: {len(schools_result['target_schools'])}ä¸ª")
        print(f"å†²åˆºå­¦æ ¡: {len(schools_result['reach_schools'])}ä¸ª")
        
        # æ­¥éª¤3: ç”Ÿæˆæ—¶é—´çº¿
        print(f"\nğŸ“… æ­¥éª¤3: ç”Ÿæˆæ—¶é—´çº¿")
        timeline_result = get_timeline(analysis_id)
        print(f"æ—¶é—´çº¿é˜¶æ®µ: {len(timeline_result['timeline'])}ä¸ª")
        print(f"æ€»ä»»åŠ¡æ•°: {timeline_result['total_tasks']}")
        
        print("\nğŸ‰ å®Œæ•´æµç¨‹æ¼”ç¤ºæˆåŠŸï¼")
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        print("\nğŸ“Š ç»“æœæ‘˜è¦:")
        print("-" * 40)
        for school in schools_result['target_schools']:
            print(f"ğŸ¯ {school['school']} - {school['program']} (åŒ¹é…åº¦: {school['match_score']}%)")
        
        for school in schools_result['reach_schools']:
            print(f"ğŸš€ {school['school']} - {school['program']} (åŒ¹é…åº¦: {school['match_score']}%)")
            
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    demo_full_flow()
